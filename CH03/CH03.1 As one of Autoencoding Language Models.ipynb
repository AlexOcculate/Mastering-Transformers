{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CH03.1 As one of Autoencoding Language Models.ipynb","provenance":[],"authorship_tag":"ABX9TyOCfxNdkgPZMLnQSB0EMnvX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"04e4ed6b23804008a864a8b52fe3cc50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0d7f8aa12198464f8ed1b29b4e0932d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0b695e9fcda34519b481ba167e91c1f0","IPY_MODEL_63f1107912fb4fbc8692999c358e225f"]}},"0d7f8aa12198464f8ed1b29b4e0932d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b695e9fcda34519b481ba167e91c1f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_82044480d6b945c3bdbab90550a3c425","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c938fdcecc934f009791ab06e2363a71"}},"63f1107912fb4fbc8692999c358e225f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b5af7e455f045dfa0b006d091c5e36c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 2.56kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa445a6ca7494021b1ed2a24bbf8136c"}},"82044480d6b945c3bdbab90550a3c425":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c938fdcecc934f009791ab06e2363a71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b5af7e455f045dfa0b006d091c5e36c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa445a6ca7494021b1ed2a24bbf8136c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e92dde540684c139648673c2229b1fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2408535ff9d64890acb7d6653d9176a4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d05211d114f24bb0a2c139911f5e9d50","IPY_MODEL_cb62a37d9989407796384610f1cc90fc"]}},"2408535ff9d64890acb7d6653d9176a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d05211d114f24bb0a2c139911f5e9d50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e773a1413ab5471095e47e8a22fd45a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec9e2ab630804d30a90e6c9e04d98660"}},"cb62a37d9989407796384610f1cc90fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc91bced129d4d5c91385a6e33029b99","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:10&lt;00:00, 50.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_435454a63ba647a89e28905432ff1d81"}},"e773a1413ab5471095e47e8a22fd45a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec9e2ab630804d30a90e6c9e04d98660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc91bced129d4d5c91385a6e33029b99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"435454a63ba647a89e28905432ff1d81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"018850455db648c19a0680f20d029f92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7bf47208d4204a1f8d1b37f9df52b7f1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5610b794036443294883a7bb269a451","IPY_MODEL_60ee12598a03467bb97c4e75fdbe7908"]}},"7bf47208d4204a1f8d1b37f9df52b7f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5610b794036443294883a7bb269a451":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ffd6314162d44e5cacb9a8fd82f9a981","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76e164e5d33241149d182b03ad284acc"}},"60ee12598a03467bb97c4e75fdbe7908":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d660fe5c91844c188bbd6d649a60b3c7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:01&lt;00:00, 126kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e197bcd0ba043c5ba633b7e20a83c4d"}},"ffd6314162d44e5cacb9a8fd82f9a981":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"76e164e5d33241149d182b03ad284acc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d660fe5c91844c188bbd6d649a60b3c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e197bcd0ba043c5ba633b7e20a83c4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d6e5fae6f7f6401ab91c0fbc12cb079d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_95887ca3980e4db297625a0695fc3644","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_209334e45784464ebcacef3fcf808d9f","IPY_MODEL_94f237a9fb544df9a4f9d34fa0670584"]}},"95887ca3980e4db297625a0695fc3644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"209334e45784464ebcacef3fcf808d9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6ff29acda89d4213a41cad61fe58fda7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a50aa86ae7e14c42b5e29d3c2387921e"}},"94f237a9fb544df9a4f9d34fa0670584":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62bd82b7be434d00b925f45a6153c383","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:01&lt;00:00, 399kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04704685749e490f869caeb2b011daa0"}},"6ff29acda89d4213a41cad61fe58fda7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a50aa86ae7e14c42b5e29d3c2387921e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62bd82b7be434d00b925f45a6153c383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04704685749e490f869caeb2b011daa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11c58b3ab35f445380fed4366a563f27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf13bd1b487e4b21a878339326866774","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_50f732e690294a8f91efe7dcf5bbce77","IPY_MODEL_97b3b0b545f143e096ab317ce2cef5d7"]}},"cf13bd1b487e4b21a878339326866774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50f732e690294a8f91efe7dcf5bbce77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b82744a6723b4669a3958d25681b0fd3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_329818bb06494dc892e15ed6d8a2d148"}},"97b3b0b545f143e096ab317ce2cef5d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45e928d5232943daab9699db96acd998","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:22&lt;00:00, 1.27B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03185b1ecbe54f61ba22f1da631a83cc"}},"b82744a6723b4669a3958d25681b0fd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"329818bb06494dc892e15ed6d8a2d148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45e928d5232943daab9699db96acd998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"03185b1ecbe54f61ba22f1da631a83cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"v61w8HXuZrLH"},"source":["# BERT: As one of Autoencoding Language Models "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXoOOoBAZqHq","executionInfo":{"status":"ok","timestamp":1619026026477,"user_tz":-180,"elapsed":994,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"1e8b1563-fe2a-4cb6-9bf8-e244b6c19c78"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3bcOfnNWJhv","executionInfo":{"status":"ok","timestamp":1619026033951,"user_tz":-180,"elapsed":6776,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"625003ba-c88d-40ac-bff6-16ba2bdf4967"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 7.4MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 36.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 51.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDuHvNUnbRXu","executionInfo":{"status":"ok","timestamp":1619026037905,"user_tz":-180,"elapsed":3542,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"4bf9fbaa-398c-4647-bdab-e7d51cb40381"},"source":["!pip install tokenizers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YR3-I4bFUVdm","executionInfo":{"status":"ok","timestamp":1619026038759,"user_tz":-180,"elapsed":1098,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["os.chdir(\"drive/MyDrive/akademi/Packt NLP with Transformers/CH03\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVadDu1T4NZF","executionInfo":{"status":"ok","timestamp":1619026040068,"user_tz":-180,"elapsed":832,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"4a43d686-aaf1-4537-ba5f-d50717a84274"},"source":["os.listdir()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['CH03.1 As one of Autoencoding Language Models.ipynb',\n"," 'IMDB Dataset.csv',\n"," 'albert.png',\n"," 'CH03.0X Autoencoding Models.ipynb',\n"," 'old files',\n"," 'CH03.0X Tokenizer.ipynb',\n"," 'corpus.txt']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"hGJiQ2Sx4mm7","executionInfo":{"status":"ok","timestamp":1619026053933,"user_tz":-180,"elapsed":588,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJbh3P-e3g0S","executionInfo":{"status":"ok","timestamp":1619026056919,"user_tz":-180,"elapsed":3085,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["import pandas as pd\n","imdb_df = pd.read_csv(\"IMDB Dataset.csv\")\n","reviews = imdb_df.review.to_string(index=None) \n","with open(\"corpus.txt\", \"w\") as f: \n","    f.writelines(reviews) "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQRzoQKS4SA2","executionInfo":{"status":"ok","timestamp":1619026061774,"user_tz":-180,"elapsed":2262,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from tokenizers import BertWordPieceTokenizer\n","bert_wordpiece_tokenizer = BertWordPieceTokenizer() \n","bert_wordpiece_tokenizer.train(\"corpus.txt\") "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"datICiehV7kv","executionInfo":{"status":"ok","timestamp":1619026063174,"user_tz":-180,"elapsed":511,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"8bf5547a-623f-4e1f-f00d-216c072c2907"},"source":["bert_wordpiece_tokenizer.get_vocab()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'##iliar': 2285,\n"," 'germans': 10744,\n"," 'shaky': 11110,\n"," 'nigel': 13408,\n"," 'list': 1340,\n"," 'spy': 5241,\n"," 'veterans': 13210,\n"," 'mitz': 14035,\n"," 'ske': 3446,\n"," 'abs': 584,\n"," '##vest': 3676,\n"," 'uncle': 5537,\n"," 'seven': 2458,\n"," 'decadent': 17952,\n"," 'catastrop': 15985,\n"," '56': 13853,\n"," '##ioklar': 15410,\n"," 'previous': 1388,\n"," 'poppa': 12696,\n"," 'affection': 11317,\n"," 'dane': 8645,\n"," 'beowulf': 9701,\n"," 'hooray': 15505,\n"," 'carey': 10612,\n"," 'kite': 6605,\n"," 'missouri': 10593,\n"," 'four': 1177,\n"," 'videostore': 15523,\n"," 'vacation': 3869,\n"," 'amanda': 8894,\n"," 'milo': 12798,\n"," 'edith': 9071,\n"," 'cabin': 5112,\n"," 'strangeland': 13504,\n"," 'deaths': 16038,\n"," 'entrails': 13705,\n"," 'lind': 3881,\n"," 'braindead': 16470,\n"," 'awful': 664,\n"," 'relate': 7488,\n"," 'gome': 13950,\n"," '##ited': 1048,\n"," '##zem': 14365,\n"," '##ter': 223,\n"," 'archbishop': 16917,\n"," 'chains': 8874,\n"," '##dle': 1795,\n"," 'zent': 8735,\n"," '##istical': 12007,\n"," '##ator': 2912,\n"," 'comedians': 7382,\n"," 'jum': 7814,\n"," 'clouds': 13541,\n"," 'ang': 1423,\n"," 'mus': 796,\n"," 'lar': 1545,\n"," 'lon': 2394,\n"," 'covered': 10741,\n"," 'kahin': 18087,\n"," 'zoey': 9661,\n"," '##hur': 5479,\n"," 'bron': 4042,\n"," 'pleasingly': 15628,\n"," '##ffiti': 10325,\n"," 'jeanette': 12880,\n"," 'elig': 15668,\n"," 'neglected': 9306,\n"," 'darius': 12801,\n"," 'doubting': 15744,\n"," 'critical': 5306,\n"," 'uwe': 4480,\n"," 'rumor': 10941,\n"," '##house': 4488,\n"," 'girlf': 2350,\n"," 'mard': 11457,\n"," 'ts': 5788,\n"," 'burtynsky': 18266,\n"," 'flamenco': 15226,\n"," 'vein': 8019,\n"," 'kevin': 2720,\n"," 'appealing': 9383,\n"," 'rajnik': 17167,\n"," 'sixtie': 16235,\n"," '##lands': 10578,\n"," '##room': 5928,\n"," 'outlandish': 11314,\n"," 'represent': 6070,\n"," 'kool': 14007,\n"," 'revolver': 16782,\n"," 'credibility': 12790,\n"," 'forms': 16315,\n"," 'psy': 1959,\n"," 'geniuses': 10785,\n"," 'alda': 13519,\n"," 'atm': 3792,\n"," '##gu': 1258,\n"," 'hollow': 5932,\n"," 'tribeca': 7755,\n"," 'survive': 11021,\n"," 'delusion': 15686,\n"," 'impressions': 15974,\n"," 'haneke': 9693,\n"," 'viewer': 3317,\n"," 'ordinary': 5114,\n"," 'whod': 6696,\n"," 'muthamittal': 13734,\n"," 'slated': 15311,\n"," 'patter': 9267,\n"," '##cul': 14331,\n"," 'bl': 443,\n"," 'delivers': 3516,\n"," 'pitt': 6179,\n"," '##ewed': 15777,\n"," 'manner': 7314,\n"," 'kane': 3654,\n"," 'valiant': 12688,\n"," 'hellman': 12574,\n"," '##wwwwwwww': 17363,\n"," 'jerem': 17143,\n"," 'pastor': 16294,\n"," 'kats': 11442,\n"," 'martha': 15473,\n"," 'patch': 12712,\n"," 'forgettable': 5654,\n"," '##ets': 1585,\n"," '##ir': 192,\n"," 'cry': 2376,\n"," 'ange': 3367,\n"," 'unquestionably': 18216,\n"," '##atisf': 14422,\n"," '##edy': 3778,\n"," '##otik': 14562,\n"," 'hobgoblins': 9711,\n"," 'whore': 14545,\n"," 'knows': 2582,\n"," 'phantasm': 9594,\n"," '##rant': 6199,\n"," 'clif': 10255,\n"," 'reviewers': 1735,\n"," 'surely': 3238,\n"," '##obs': 9914,\n"," 'dak': 9761,\n"," '##odile': 10181,\n"," '##ooooo': 12966,\n"," 'wealthy': 5432,\n"," 'disposable': 18038,\n"," '##ug': 2166,\n"," 'overwhel': 6564,\n"," 'lyn': 2648,\n"," 'flow': 4990,\n"," '##ler': 1554,\n"," 'timing': 11999,\n"," 'hen': 2485,\n"," 'detective': 3644,\n"," 'flashdance': 8381,\n"," 'boot': 6817,\n"," 'austin': 6392,\n"," 'films': 394,\n"," 'oriented': 8617,\n"," 'everythin': 11068,\n"," 'nicolas': 5082,\n"," 'orth': 12127,\n"," 'lad': 3655,\n"," 'traci': 10396,\n"," 'powe': 12549,\n"," 'thaw': 9954,\n"," '##lection': 7239,\n"," 'screams': 16899,\n"," 'weaves': 14781,\n"," 'berg': 3731,\n"," 'jacquel': 7011,\n"," 'tearful': 16805,\n"," 'det': 1623,\n"," 'bible': 7794,\n"," 'centres': 16178,\n"," 'caps': 13892,\n"," 'chad': 14749,\n"," '##stairs': 18155,\n"," 'lorenzo': 9436,\n"," 'clarke': 17097,\n"," '##ters': 1667,\n"," 'francois': 8389,\n"," '##end': 456,\n"," 'dukes': 6904,\n"," 'jeffersons': 17806,\n"," 'domin': 4456,\n"," 'weren': 5383,\n"," '##ned': 1127,\n"," 'awaited': 7668,\n"," '##inton': 15228,\n"," 'minute': 2216,\n"," 'loony': 11900,\n"," '##ius': 2167,\n"," 'biggest': 1802,\n"," 'scint': 14923,\n"," 'mayer': 15260,\n"," 'dressing': 16800,\n"," 'inte': 3930,\n"," 'transcend': 17818,\n"," 'shown': 2095,\n"," 'engineer': 17538,\n"," 'manipu': 18192,\n"," '##wis': 11604,\n"," '##inek': 15152,\n"," 'instantly': 10698,\n"," 'featur': 7473,\n"," '##ora': 4934,\n"," 'particu': 16360,\n"," 'aard': 8629,\n"," 'turtle': 16190,\n"," 'jaded': 6163,\n"," '##ign': 1442,\n"," 'opt': 6175,\n"," 'roach': 8973,\n"," 'zipp': 11552,\n"," 'hokey': 10444,\n"," 'slop': 6324,\n"," 'crazy': 2504,\n"," 'thir': 2845,\n"," 'partner': 6814,\n"," 'interpreted': 9653,\n"," 'sleep': 3513,\n"," 'carlos': 4824,\n"," 'colon': 8139,\n"," 'litera': 16535,\n"," 'scor': 3294,\n"," 'australian': 2319,\n"," 'remains': 4535,\n"," 'spend': 2623,\n"," '##cemi': 14699,\n"," 'donnell': 12061,\n"," 'frozen': 12871,\n"," 'anarch': 14488,\n"," 'deranged': 10852,\n"," 'embezz': 15612,\n"," 'tuscan': 13769,\n"," 'strang': 7417,\n"," '30': 1739,\n"," '##elic': 10124,\n"," 'perfec': 13355,\n"," 'awwww': 15151,\n"," 'disk': 10282,\n"," 'further': 4844,\n"," 'pet': 1138,\n"," 'tony': 3557,\n"," 'montano': 13818,\n"," 'conne': 4970,\n"," 'd': 46,\n"," 'holmes': 4760,\n"," 'agg': 8947,\n"," 'frost': 3578,\n"," 'mindless': 6863,\n"," 'karl': 10748,\n"," 'woody': 3079,\n"," 'sc': 297,\n"," 'tomatoes': 9680,\n"," 'shou': 6250,\n"," 'tripe': 9214,\n"," 'sou': 5784,\n"," 'infomer': 16207,\n"," 'magoo': 12737,\n"," 'fictional': 4813,\n"," 'ps': 11482,\n"," 'rival': 7169,\n"," 'unease': 16618,\n"," 'equal': 13367,\n"," 'malefique': 13232,\n"," 'followin': 15707,\n"," 'ambient': 17090,\n"," '##mont': 14228,\n"," 'cary': 6150,\n"," '##med': 1941,\n"," 'packed': 4610,\n"," 'gentlemen': 5102,\n"," '##e': 92,\n"," 'mishima': 9529,\n"," 'rosie': 9455,\n"," 'ser': 409,\n"," 'unimp': 11017,\n"," 'theatre': 3827,\n"," 'undou': 3060,\n"," 'herbie': 12330,\n"," 'scripts': 12530,\n"," 'pan': 2607,\n"," '##wre': 11605,\n"," 'couldnt': 10328,\n"," '##kers': 9898,\n"," 'him': 2043,\n"," '##uso': 10308,\n"," 'althoug': 12304,\n"," 'es': 4303,\n"," '##gh': 188,\n"," '##tigo': 9878,\n"," 'skeleton': 13097,\n"," 'anticipate': 17215,\n"," 'paris': 2723,\n"," 'misadvent': 15560,\n"," 'debating': 16214,\n"," 'robbie': 15146,\n"," 'hay': 3099,\n"," 'skeptic': 13096,\n"," 'tarzan': 3080,\n"," 'z': 68,\n"," 'mex': 2794,\n"," 'happiest': 15610,\n"," 'resist': 9243,\n"," 'gang': 2331,\n"," 'www': 10784,\n"," 'satirical': 9595,\n"," '1h': 11338,\n"," 'footie': 16370,\n"," 'nifty': 11288,\n"," 'cyb': 13092,\n"," 'sorority': 13706,\n"," 'loesser': 13787,\n"," 'milan': 12799,\n"," 'delive': 10524,\n"," 'sleepers': 16877,\n"," '##vincing': 16143,\n"," 'scales': 17624,\n"," 'unimaginative': 7759,\n"," 'stupi': 12526,\n"," 'exch': 11887,\n"," 'vi': 1518,\n"," '##hopper': 18145,\n"," 'effort': 1933,\n"," 'experiences': 8384,\n"," '##ass': 448,\n"," '##ios': 2402,\n"," '##do': 5197,\n"," 'historian': 10742,\n"," 'practice': 7670,\n"," 'breaker': 9228,\n"," 'loess': 11898,\n"," 'fare': 4065,\n"," 'grandma': 16517,\n"," 'foremost': 4866,\n"," 'thursday': 6559,\n"," 'surprises': 5919,\n"," 'recounts': 18227,\n"," 'thoug': 4261,\n"," '##cus': 6209,\n"," 'stone': 3370,\n"," 'symbolism': 9684,\n"," 'today': 1424,\n"," '##ining': 11676,\n"," 'ignor': 6983,\n"," 'unfor': 7343,\n"," 'defiant': 10462,\n"," 'description': 4863,\n"," 'invigorating': 16629,\n"," 'retarded': 5045,\n"," '##ced': 1016,\n"," 'mst': 3191,\n"," '##odu': 624,\n"," 'fortune': 12945,\n"," 'unseen': 8585,\n"," 'republican': 18265,\n"," 'something': 946,\n"," 'gle': 9777,\n"," 'unrated': 15030,\n"," 'post': 1343,\n"," 'adaptations': 4220,\n"," '##gger': 7527,\n"," '##led': 944,\n"," 'familiar': 2419,\n"," 'diam': 5252,\n"," 'beginni': 9052,\n"," 'europe': 2434,\n"," 'lud': 4467,\n"," 'clipped': 15062,\n"," 'colour': 9082,\n"," 'shat': 8854,\n"," 'rive': 4477,\n"," 'route': 16913,\n"," '##gy': 2365,\n"," 'tollinger': 18158,\n"," 'freaks': 17427,\n"," 'raho': 18118,\n"," 'whack': 14546,\n"," 'shel': 4043,\n"," 'bert': 11357,\n"," 'shrek': 7691,\n"," 'syn': 2449,\n"," 'rel': 1064,\n"," 'defi': 9092,\n"," 'relative': 3326,\n"," 'refres': 4419,\n"," 'mys': 7272,\n"," 'wholehearted': 15959,\n"," '##otely': 8826,\n"," 'complete': 1580,\n"," 'rugged': 15698,\n"," 'ham': 2497,\n"," 'jealousy': 17974,\n"," '##iao': 15434,\n"," '##ium': 5194,\n"," 'reco': 12194,\n"," 'haifa': 18161,\n"," 'chicken': 16894,\n"," 'fantasti': 11041,\n"," 'deceptively': 13494,\n"," '##rian': 4342,\n"," 'slim': 8103,\n"," 'study': 3500,\n"," 'gimmick': 9692,\n"," '##ifying': 8136,\n"," 'difficulties': 16283,\n"," 'ein': 8648,\n"," '##esy': 14572,\n"," 'cassie': 16591,\n"," 'ingenious': 13715,\n"," 'relates': 12499,\n"," 'own': 1489,\n"," 'lake': 4657,\n"," 'jones': 3170,\n"," 'jew': 3653,\n"," 'experim': 6880,\n"," 'monot': 15590,\n"," 'cri': 5442,\n"," '##antino': 4968,\n"," '##ificent': 4608,\n"," 'til': 6626,\n"," 'nod': 14042,\n"," 'shak': 6252,\n"," 'flavia': 8563,\n"," 'threads': 16934,\n"," 'scoop': 8910,\n"," 'clerk': 15064,\n"," 'yourself': 5015,\n"," 'overlong': 7644,\n"," '##de': 572,\n"," '##cially': 8096,\n"," 'commiss': 15785,\n"," 'spoil': 416,\n"," '##hip': 9912,\n"," 'prime': 4710,\n"," 'ex': 233,\n"," '##anos': 4693,\n"," 'solino': 18181,\n"," '##ogra': 4199,\n"," 'hooked': 4652,\n"," 'plane': 3586,\n"," '##ounding': 3937,\n"," 'haz': 7253,\n"," '##leon': 14555,\n"," 'enjo': 6304,\n"," 'elder': 6587,\n"," 'attended': 4203,\n"," 'follows': 2186,\n"," 'occ': 2448,\n"," 'clubbed': 13042,\n"," 'beca': 4532,\n"," 'soda': 14786,\n"," 'montgo': 13119,\n"," 'rout': 3661,\n"," 'misses': 7509,\n"," '##avier': 9076,\n"," '##ien': 561,\n"," 'alright': 2748,\n"," 'petites': 15814,\n"," 'kh': 11430,\n"," '##cher': 4951,\n"," 'destruction': 11973,\n"," 'wro': 15118,\n"," 'aint': 13864,\n"," 'villain': 10876,\n"," 'campfire': 16164,\n"," 'teen': 1089,\n"," '##lym': 11729,\n"," 'nazis': 10999,\n"," '##pr': 2611,\n"," 'sorts': 6901,\n"," 'fini': 15375,\n"," 'nomad': 11154,\n"," 'herd': 15502,\n"," 'guard': 6807,\n"," 'wast': 6703,\n"," 'complaints': 8390,\n"," 'isl': 14455,\n"," 'fiction': 1772,\n"," '##rin': 4676,\n"," 'fierce': 9019,\n"," 'fert': 11401,\n"," 'depart': 7515,\n"," '##manuelle': 13803,\n"," 'possibly': 1391,\n"," 'excessive': 17970,\n"," '##ider': 933,\n"," 'affect': 12032,\n"," '1981': 4767,\n"," 'veteran': 5717,\n"," 'mel': 1475,\n"," '##ural': 2923,\n"," 'ap': 1251,\n"," 'infor': 3202,\n"," 'fairbanks': 15851,\n"," 'usa': 3808,\n"," 'scud': 14922,\n"," 'vote': 4022,\n"," 'bel': 495,\n"," 'youngster': 12275,\n"," 'criticism': 4244,\n"," 'catal': 9227,\n"," 'basicall': 12894,\n"," 'awesomely': 13570,\n"," 'splendidly': 17263,\n"," 'die': 1758,\n"," 'pair': 7471,\n"," '##otting': 10522,\n"," 'doub': 9113,\n"," 'august': 7727,\n"," 'sai': 8865,\n"," '##udrama': 10275,\n"," 'deserted': 16122,\n"," 'sailing': 14739,\n"," 'comment': 491,\n"," '##cer': 1452,\n"," 'subjects': 10721,\n"," 'intermittently': 18255,\n"," 'joel': 7368,\n"," 'disagreed': 16497,\n"," '##ban': 4927,\n"," 'machine': 4117,\n"," '##lig': 7192,\n"," '##iel': 2170,\n"," 'spanish': 3526,\n"," 'polly': 15833,\n"," 'charlton': 16385,\n"," 'alan': 3131,\n"," 'worl': 7290,\n"," '##inrid': 11680,\n"," 'historical': 2727,\n"," 'abhay': 11858,\n"," 'phenix': 13243,\n"," '##hurst': 13341,\n"," 'combs': 11874,\n"," '##hut': 14297,\n"," 'gesp': 13961,\n"," 'sink': 7171,\n"," 'prospect': 13418,\n"," 'dinosa': 3860,\n"," 'boogeyman': 16433,\n"," '##eris': 9955,\n"," '##gers': 3770,\n"," 'dresser': 9435,\n"," 'amidst': 11941,\n"," 'theflickguy': 18308,\n"," '##lesc': 15503,\n"," '##inqu': 14412,\n"," 'freebird': 10760,\n"," 'lumiere': 13282,\n"," 'poison': 10223,\n"," 'potential': 1890,\n"," 'tentative': 18122,\n"," 'budget': 964,\n"," 'haw': 4041,\n"," 'opinions': 7528,\n"," 'deborah': 16215,\n"," 'genr': 12272,\n"," 'offers': 3942,\n"," 'pyaar': 18115,\n"," 'chase': 4173,\n"," 'bach': 3346,\n"," 'kari': 12817,\n"," 'brien': 7956,\n"," 'ton': 2262,\n"," 'extraordina': 13088,\n"," 'interes': 6383,\n"," 'burles': 16028,\n"," 'v': 64,\n"," 'fantasies': 16341,\n"," 'grabbed': 8548,\n"," 'clark': 4724,\n"," '##used': 2124,\n"," 'indicate': 15781,\n"," 'fai': 15013,\n"," 'turgid': 7562,\n"," '##ghter': 8860,\n"," 'barbra': 6446,\n"," 'misadventures': 18243,\n"," '##ks': 1373,\n"," 'about': 239,\n"," 'tenuous': 15888,\n"," 'moment': 1665,\n"," 'cham': 6259,\n"," 'emotionally': 5657,\n"," 'emperor': 7462,\n"," 'danner': 15837,\n"," 'bubbling': 17644,\n"," 'abra': 11856,\n"," 'sie': 5783,\n"," 'maguire': 14962,\n"," 'whe': 2140,\n"," 'sematary': 8368,\n"," 'mishmash': 11032,\n"," 'now': 628,\n"," 'lond': 2395,\n"," 'ret': 1158,\n"," 'arguably': 3863,\n"," 'remarked': 16487,\n"," 'doom': 11945,\n"," 'hung': 5056,\n"," 'streep': 5503,\n"," 'lackawanna': 5732,\n"," 'inde': 1427,\n"," 'vier': 9858,\n"," 'vigilante': 13487,\n"," 'airwolf': 16238,\n"," 'sword': 5311,\n"," '##uli': 6258,\n"," 'o': 57,\n"," 'european': 3850,\n"," 'mins': 15332,\n"," 'fifties': 13810,\n"," 'gate': 5759,\n"," 'toronto': 3019,\n"," 'bus': 2291,\n"," 'sons': 9840,\n"," '##ench': 1194,\n"," '##ages': 5271,\n"," '##ior': 3282,\n"," '##itting': 1799,\n"," '##igan': 4721,\n"," 'versions': 5295,\n"," '##zene': 11648,\n"," 'haired': 11814,\n"," 'artemisia': 17964,\n"," 'christina': 9148,\n"," 'clon': 10252,\n"," 'previewed': 16193,\n"," 'totally': 1240,\n"," 'best': 352,\n"," 'perfo': 7376,\n"," 'concept': 1948,\n"," 'code': 3647,\n"," 'komodo': 9629,\n"," 'revelation': 11109,\n"," 'gill': 5154,\n"," 'laced': 11455,\n"," 'krabbe': 17516,\n"," 'unsure': 10889,\n"," 'nolte': 17011,\n"," 'sorte': 16061,\n"," 'igor': 13985,\n"," 'exhilar': 13446,\n"," 'swallow': 15825,\n"," '1916': 16967,\n"," '##verse': 4337,\n"," 'imaginary': 6389,\n"," 'broug': 14646,\n"," 'pity': 5463,\n"," '##ingers': 4940,\n"," 'unappe': 15037,\n"," 'lupino': 9111,\n"," 'chorus': 8560,\n"," 'hungary': 9542,\n"," 'mundane': 13761,\n"," 'carr': 4744,\n"," 'intense': 3300,\n"," '##zov': 14368,\n"," 'heck': 4189,\n"," '##ker': 2200,\n"," 'chock': 8872,\n"," 'murd': 4227,\n"," 'homm': 11417,\n"," 'before': 600,\n"," 'rodney': 8405,\n"," '1930': 4234,\n"," 'sus': 2577,\n"," 'oldboy': 9043,\n"," 'memories': 3625,\n"," 'clarks': 17122,\n"," 'ses': 14106,\n"," 'tim': 303,\n"," 'cereb': 17441,\n"," 'disp': 8056,\n"," 'raped': 13134,\n"," 'bedkno': 10817,\n"," '##ome': 667,\n"," 'crispin': 11115,\n"," 'ody': 5772,\n"," 'scalp': 17623,\n"," 'deci': 11970,\n"," 'casey': 16194,\n"," 'wallace': 6515,\n"," 'sud': 8879,\n"," 'wizards': 17507,\n"," 'driver': 8253,\n"," 'votes': 9373,\n"," 'among': 2071,\n"," 'williams': 3416,\n"," 'camera': 3081,\n"," 'friendship': 6344,\n"," 'wondr': 12244,\n"," 'voices': 16611,\n"," '##omai': 14538,\n"," 'ostensibly': 6556,\n"," 'corbett': 13396,\n"," '##master': 7866,\n"," 'que': 6780,\n"," 'wynorski': 7761,\n"," 'avery': 16188,\n"," 'head': 1668,\n"," 'god': 960,\n"," 'whats': 10141,\n"," 'brad': 3208,\n"," 'thinki': 10266,\n"," '##eer': 4481,\n"," 'demented': 8255,\n"," 'remember': 611,\n"," 'inventive': 7654,\n"," '##ishingly': 10286,\n"," 'inse': 6693,\n"," 'prett': 7404,\n"," 'delete': 17540,\n"," '##ppel': 8935,\n"," 'piznars': 17711,\n"," 'sophom': 13110,\n"," 'gorge': 3749,\n"," 'phenomenon': 8525,\n"," 'seaman': 14608,\n"," 'hillarious': 16986,\n"," 'guit': 15306,\n"," 'writt': 1029,\n"," 'dylan': 5447,\n"," '##ersome': 11884,\n"," 'costner': 12874,\n"," 'ste': 641,\n"," 'raunchily': 17976,\n"," 'gett': 8980,\n"," 'notion': 11845,\n"," 'scar': 1984,\n"," 'extrem': 1155,\n"," 'former': 3123,\n"," 'kust': 14002,\n"," 'feelgood': 12390,\n"," 'dreck': 5958,\n"," 'minutes': 1073,\n"," 'those': 508,\n"," '##atsi': 6949,\n"," '##atnam': 14423,\n"," 'grabbing': 17354,\n"," 'hbo': 2293,\n"," 'helen': 6916,\n"," 'elmore': 12450,\n"," 'chab': 8871,\n"," 'bath': 7111,\n"," '##fan': 7207,\n"," '##esar': 10024,\n"," 'versatile': 15507,\n"," 'ray': 2488,\n"," '91': 8627,\n"," 'intrigue': 10761,\n"," 'bewildering': 13627,\n"," 'grain': 16033,\n"," '1914': 13158,\n"," '##syl': 12672,\n"," 'thourough': 18151,\n"," 'anton': 3780,\n"," 'parody': 3957,\n"," '1920s': 8372,\n"," 'sri': 14108,\n"," 'cr': 446,\n"," '##oral': 8801,\n"," 'norm': 1430,\n"," 'audrey': 16125,\n"," 'possib': 8141,\n"," 'neg': 1829,\n"," 'financial': 17639,\n"," 'sake': 11875,\n"," 'chaplin': 3175,\n"," 'characterization': 9208,\n"," 'franc': 12711,\n"," 'fernando': 18028,\n"," 'naruto': 13309,\n"," 'winch': 5634,\n"," 'aerial': 18051,\n"," 'apprecia': 16526,\n"," 'darling': 9316,\n"," 'progr': 2209,\n"," '##mmet': 15508,\n"," 'limerick': 13784,\n"," 'stud': 1038,\n"," 'hilarious': 1345,\n"," '##ki': 2017,\n"," 'toky': 11726,\n"," 'eisenstein': 7708,\n"," 'responsi': 17213,\n"," 'cringing': 17202,\n"," '##ious': 410,\n"," 'camping': 7555,\n"," 'frust': 3212,\n"," 'advance': 7620,\n"," 'several': 1161,\n"," 'stall': 7246,\n"," 'includin': 16489,\n"," 'imperial': 17630,\n"," 'annoy': 2595,\n"," 'horr': 454,\n"," 'bott': 2691,\n"," 'eastern': 6588,\n"," 'beckinsale': 11276,\n"," 'unfun': 3615,\n"," '##aka': 15092,\n"," 'punch': 7648,\n"," 'exceptionally': 7554,\n"," 'biop': 4236,\n"," 'pill': 11484,\n"," 'itali': 11771,\n"," '##ified': 4206,\n"," 'chann': 12317,\n"," '£3': 14191,\n"," 'moviegoers': 17883,\n"," 'une': 2710,\n"," '1938': 9222,\n"," 'fraulein': 17901,\n"," 'woodward': 16137,\n"," 'dtv': 13911,\n"," 'filmmake': 12764,\n"," '##op': 258,\n"," '##ote': 1000,\n"," 'pennsyl': 13371,\n"," 'involve': 10772,\n"," 'stag': 7949,\n"," 'piz': 9823,\n"," 'fontaine': 9606,\n"," 'illuminated': 7734,\n"," 'pays': 14071,\n"," 'strict': 5010,\n"," 'viewed': 2099,\n"," 'fondly': 9385,\n"," 'experiments': 9620,\n"," '##andark': 8922,\n"," 'kings': 6167,\n"," '##cc': 975,\n"," 'stormy': 12654,\n"," '##ria': 10106,\n"," 'greek': 4512,\n"," '##dom': 6653,\n"," 'traumat': 17564,\n"," '##kel': 4704,\n"," 'cyborgs': 17812,\n"," 'mountainous': 16909,\n"," 'kahn': 7661,\n"," 'borderline': 13503,\n"," '##ioni': 5847,\n"," 'regardless': 10802,\n"," 'drummond': 17293,\n"," 'beep': 11744,\n"," '##ions': 1826,\n"," 'flynn': 4837,\n"," 'opening': 1469,\n"," 'briggs': 11084,\n"," 'brutal': 5404,\n"," 'pall': 11486,\n"," 'rebecca': 13662,\n"," 'shield': 11850,\n"," 'lust': 11448,\n"," '##sto': 9984,\n"," 'superbly': 5071,\n"," 'skelet': 16859,\n"," 'babylon': 12928,\n"," 'stretches': 17593,\n"," '##icus': 7243,\n"," 'milligan': 8299,\n"," 'are': 307,\n"," 'entered': 6835,\n"," 'manager': 9300,\n"," '##ague': 2469,\n"," 'followed': 5611,\n"," '##boo': 14340,\n"," 'shell': 11849,\n"," 'sunsh': 4805,\n"," 'unem': 12042,\n"," 'tomb': 9209,\n"," 'sleepy': 16876,\n"," 'combine': 7579,\n"," 'girlfrien': 16491,\n"," '##van': 7205,\n"," 'pray': 7985,\n"," 'quiet': 3806,\n"," 'veter': 4314,\n"," 'mister': 10464,\n"," 'suspension': 12804,\n"," '##ribly': 2811,\n"," '##tr': 11556,\n"," 'amis': 14852,\n"," 'shop': 3465,\n"," 'zipper': 17881,\n"," '##int': 475,\n"," '##le': 172,\n"," 'extreme': 4781,\n"," 'offends': 15240,\n"," 'bare': 6579,\n"," 'bearing': 16779,\n"," 'illustration': 13631,\n"," 'aaron': 7740,\n"," 'milk': 16302,\n"," '##icy': 14566,\n"," 'daddy': 10830,\n"," 'nea': 10162,\n"," 'þ': 87,\n"," 'overcoming': 15272,\n"," 'popeye': 13828,\n"," 'kick': 2896,\n"," 'succinct': 16109,\n"," '##foe': 9949,\n"," 'myra': 11862,\n"," 'travis': 15386,\n"," 'intrig': 16400,\n"," '##aly': 3560,\n"," 'molasses': 17528,\n"," '##etta': 11839,\n"," 'pitiful': 9698,\n"," '##ud': 388,\n"," '##ong': 390,\n"," '##ched': 3784,\n"," 'dealing': 5093,\n"," 'dogg': 11947,\n"," 'liberties': 18172,\n"," 'johan': 15164,\n"," 'despit': 12513,\n"," 'exc': 1204,\n"," 'housewi': 7485,\n"," 'tracy': 5006,\n"," 'ewoks': 18065,\n"," 'diplomatic': 17741,\n"," 'questio': 10652,\n"," 'prair': 11917,\n"," 'inan': 14520,\n"," 'happening': 6844,\n"," 'presentation': 5371,\n"," 'argentina': 16953,\n"," '##dowell': 9662,\n"," '##itko': 9992,\n"," 'tromeo': 9706,\n"," 'apo': 3747,\n"," 'positive': 1836,\n"," 'stev': 15419,\n"," 'shlock': 14687,\n"," 'ability': 7270,\n"," 'noi': 14974,\n"," 'difficult': 1870,\n"," '##lish': 1596,\n"," 'ros': 3591,\n"," 'fashioned': 5701,\n"," 'misrepresent': 18047,\n"," 'attem': 10428,\n"," 'rks': 14100,\n"," '##hero': 6765,\n"," 'unintentionally': 9650,\n"," 'unint': 3588,\n"," 'thal': 14385,\n"," 'creative': 5947,\n"," 'again': 762,\n"," '##ino': 1522,\n"," 'half': 1187,\n"," 'woe': 8242,\n"," 'dy': 11377,\n"," '##ision': 14398,\n"," '##dad': 6654,\n"," '##og': 577,\n"," 'alice': 3923,\n"," 'crooked': 12157,\n"," 'memorable': 3517,\n"," 'syriana': 16119,\n"," '##ik': 3562,\n"," '##vel': 675,\n"," '##erpt': 14404,\n"," 'whol': 8822,\n"," 'seeing': 654,\n"," 'sooo': 13441,\n"," 'satu': 15636,\n"," 'advanced': 9391,\n"," 'interminable': 18253,\n"," 'kinds': 5297,\n"," '##ardieu': 8934,\n"," 'carp': 2802,\n"," 'gran': 12181,\n"," 'piggy': 16962,\n"," '##yrati': 17720,\n"," 'ridic': 1867,\n"," 'robiche': 16167,\n"," 'gary': 3350,\n"," 'levin': 10303,\n"," 'cheer': 5923,\n"," 'concur': 9460,\n"," 'vega': 12005,\n"," 'sorrow': 15816,\n"," 'bedroom': 7615,\n"," 'ju': 1814,\n"," '##functional': 9655,\n"," '##yll': 14326,\n"," 'florinda': 17205,\n"," '##ache': 12366,\n"," 'autob': 4618,\n"," 'esteve': 8359,\n"," 'steve': 1882,\n"," 'unless': 3477,\n"," ...}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIID_rquXa37","executionInfo":{"status":"ok","timestamp":1619026065549,"user_tz":-180,"elapsed":692,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"9bf6a6e8-3054-447b-903e-1bfcc5eacb3a"},"source":["!mkdir tokenizer\n","bert_wordpiece_tokenizer.save_model(\"tokenizer\")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tokenizer/vocab.txt']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"JF5_gklbXeeu","executionInfo":{"status":"ok","timestamp":1619026196034,"user_tz":-180,"elapsed":743,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["tokenizer = BertWordPieceTokenizer.from_file(\"tokenizer/vocab.txt\")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaKwOs23boQh","executionInfo":{"status":"ok","timestamp":1619026197446,"user_tz":-180,"elapsed":720,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":[""],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-ANSWWKXz29","executionInfo":{"status":"ok","timestamp":1619026198499,"user_tz":-180,"elapsed":498,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["tokenized_sentence = tokenizer.encode(\"Oh it works just fine\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hC11u5e-X35m","executionInfo":{"status":"ok","timestamp":1619026199630,"user_tz":-180,"elapsed":491,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"d307f56c-ae6b-43f7-bee9-3b19d83f077a"},"source":["tokenized_sentence.tokens"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]', 'oh', 'it', 'works', 'just', 'fine', '[SEP]']"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"0f5gF5m4X5m9","executionInfo":{"status":"ok","timestamp":1619026202025,"user_tz":-180,"elapsed":793,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["tokenized_sentence = tokenizer.encode(\"ohoh i thougt it might be workingg well\")"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7-Nt9n2YA8E","executionInfo":{"status":"ok","timestamp":1619026203537,"user_tz":-180,"elapsed":937,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from transformers import BertTokenizerFast \n","tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer\") "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHwTfLvKYGKA","executionInfo":{"status":"ok","timestamp":1619026213251,"user_tz":-180,"elapsed":7402,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"b845b2e1-41a8-4f9a-e1bc-ad558ea0f63f"},"source":["from transformers import LineByLineTextDataset \n","dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path=\"corpus.txt\", block_size=128) "],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"njU0BD1UYMVE","executionInfo":{"status":"ok","timestamp":1619026213253,"user_tz":-180,"elapsed":5285,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from transformers import DataCollatorForLanguageModeling \n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15) "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBM3SvrHYTNH","executionInfo":{"status":"ok","timestamp":1619026213254,"user_tz":-180,"elapsed":1140,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from transformers import TrainingArguments \n","training_args = TrainingArguments(output_dir=\"BERT\", overwrite_output_dir=True, num_train_epochs=1, per_device_train_batch_size=128) "],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"_u5_N_-9YYqw","executionInfo":{"status":"ok","timestamp":1619026218137,"user_tz":-180,"elapsed":3946,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from transformers import BertConfig, BertForMaskedLM \n","bert = BertForMaskedLM(BertConfig()) "],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQY0-ZLvYYtm","executionInfo":{"status":"ok","timestamp":1619026226304,"user_tz":-180,"elapsed":7418,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from transformers import Trainer \n","trainer = Trainer(model=bert, args=training_args, data_collator=data_collator, train_dataset=dataset) "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"bVZDxhXBYYym","executionInfo":{"status":"ok","timestamp":1619026414180,"user_tz":-180,"elapsed":185189,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"20f830f9-10db-4145-ead8-19a99226a552"},"source":["trainer.train()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [391/391 03:03, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=391, training_loss=5.399562669836956, metrics={'train_runtime': 183.9047, 'train_samples_per_second': 2.126, 'total_flos': 809001393842448.0, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': 1978449920, 'init_mem_gpu_alloc_delta': 439194112, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 16642048, 'train_mem_gpu_alloc_delta': 1324854272, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 7558385664})"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"6uzttHnJYY1C","executionInfo":{"status":"ok","timestamp":1619026418960,"user_tz":-180,"elapsed":2602,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["trainer.save_model(\"MyBERT\")"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-j4LqJHYs0F","executionInfo":{"status":"ok","timestamp":1619026422134,"user_tz":-180,"elapsed":781,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"d08c089c-2760-4149-8747-811b0df33d4f"},"source":["from transformers import BertConfig \n","BertConfig() "],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyY0_v-eYs2k","executionInfo":{"status":"ok","timestamp":1619026425752,"user_tz":-180,"elapsed":697,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"f72dd547-0d38-43a0-f1c2-680eaa4c2dc6"},"source":["tiny_bert_config = BertConfig(max_position_embeddings=512, hidden_size=128, num_attention_heads=2, num_hidden_layers=2, intermediate_size=512) \n","tiny_bert_config "],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 128,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 512,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 2,\n","  \"num_hidden_layers\": 2,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"ByC2zBtwYs44","executionInfo":{"status":"ok","timestamp":1619026454140,"user_tz":-180,"elapsed":27408,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"bf381838-8ec0-45b9-b2a7-5ce5a9a6daf2"},"source":["tiny_bert = BertForMaskedLM(tiny_bert_config) \n","trainer = Trainer(model=tiny_bert, args=training_args, data_collator=data_collator, train_dataset=dataset) \n","trainer.train() "],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [391/391 00:25, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=391, training_loss=8.822054577605499, metrics={'train_runtime': 25.8968, 'train_samples_per_second': 15.098, 'total_flos': 32626925464848.0, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 17671168, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 8192, 'train_mem_gpu_alloc_delta': 53066240, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 3202919424})"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397,"referenced_widgets":["04e4ed6b23804008a864a8b52fe3cc50","0d7f8aa12198464f8ed1b29b4e0932d3","0b695e9fcda34519b481ba167e91c1f0","63f1107912fb4fbc8692999c358e225f","82044480d6b945c3bdbab90550a3c425","c938fdcecc934f009791ab06e2363a71","1b5af7e455f045dfa0b006d091c5e36c","aa445a6ca7494021b1ed2a24bbf8136c","9e92dde540684c139648673c2229b1fe","2408535ff9d64890acb7d6653d9176a4","d05211d114f24bb0a2c139911f5e9d50","cb62a37d9989407796384610f1cc90fc","e773a1413ab5471095e47e8a22fd45a8","ec9e2ab630804d30a90e6c9e04d98660","bc91bced129d4d5c91385a6e33029b99","435454a63ba647a89e28905432ff1d81","018850455db648c19a0680f20d029f92","7bf47208d4204a1f8d1b37f9df52b7f1","a5610b794036443294883a7bb269a451","60ee12598a03467bb97c4e75fdbe7908","ffd6314162d44e5cacb9a8fd82f9a981","76e164e5d33241149d182b03ad284acc","d660fe5c91844c188bbd6d649a60b3c7","1e197bcd0ba043c5ba633b7e20a83c4d","d6e5fae6f7f6401ab91c0fbc12cb079d","95887ca3980e4db297625a0695fc3644","209334e45784464ebcacef3fcf808d9f","94f237a9fb544df9a4f9d34fa0670584","6ff29acda89d4213a41cad61fe58fda7","a50aa86ae7e14c42b5e29d3c2387921e","62bd82b7be434d00b925f45a6153c383","04704685749e490f869caeb2b011daa0","11c58b3ab35f445380fed4366a563f27","cf13bd1b487e4b21a878339326866774","50f732e690294a8f91efe7dcf5bbce77","97b3b0b545f143e096ab317ce2cef5d7","b82744a6723b4669a3958d25681b0fd3","329818bb06494dc892e15ed6d8a2d148","45e928d5232943daab9699db96acd998","03185b1ecbe54f61ba22f1da631a83cc"]},"id":"fMCmbDfFYs_s","executionInfo":{"status":"ok","timestamp":1619026483171,"user_tz":-180,"elapsed":20048,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"e232e2ef-1683-417e-b7b8-0053488cfe27"},"source":["from transformers import TFBertModel, BertTokenizerFast \n","bert = TFBertModel.from_pretrained(\"bert-base-uncased\") \n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") \n","bert.layers "],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04e4ed6b23804008a864a8b52fe3cc50","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e92dde540684c139648673c2229b1fe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"018850455db648c19a0680f20d029f92","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6e5fae6f7f6401ab91c0fbc12cb079d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11c58b3ab35f445380fed4366a563f27","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7faa6da9e250>]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-tQO7EbYtCR","executionInfo":{"status":"ok","timestamp":1619026491386,"user_tz":-180,"elapsed":762,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"a7d1d245-4f7f-4907-850a-11e6c8acda04"},"source":["tokenized_text = tokenizer.batch_encode_plus([\"hello how is it going with you\",\"lets test it\"], return_tensors=\"tf\", max_length=256, truncation=True, pad_to_max_length=True) \n","bert(tokenized_text) "],"execution_count":32,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TFBaseModelOutputWithPooling([('last_hidden_state',\n","                               <tf.Tensor: shape=(2, 256, 768), dtype=float32, numpy=\n","                               array([[[ 1.00471266e-01,  6.77026808e-02, -8.33596289e-02, ...,\n","                                        -4.93304521e-01,  1.16539374e-01,  2.26647303e-01],\n","                                       [ 3.23624015e-01,  3.70718539e-01,  6.14685655e-01, ...,\n","                                        -6.27267420e-01,  3.79082859e-01,  7.05310851e-02],\n","                                       [ 1.99534193e-01, -8.75509858e-01, -6.47859275e-02, ...,\n","                                        -1.28073208e-02,  3.07651341e-01, -2.07320880e-02],\n","                                       ...,\n","                                       [-6.53303489e-02,  1.19046137e-01,  5.76847017e-01, ...,\n","                                        -2.95460761e-01,  2.49741450e-02,  1.13964267e-01],\n","                                       [-2.64715284e-01, -7.86380544e-02,  5.47281504e-01, ...,\n","                                        -1.37515292e-01, -5.94687760e-02, -5.17925918e-02],\n","                                       [-2.44958967e-01, -1.14799500e-01,  5.92174590e-01, ...,\n","                                        -1.56881675e-01, -3.39753889e-02, -8.46135616e-02]],\n","                               \n","                                      [[ 2.94566210e-02,  2.30868444e-01,  2.92651623e-01, ...,\n","                                        -1.30421788e-01,  1.89659238e-01,  4.68428761e-01],\n","                                       [ 1.70523214e+00,  6.91359282e-01,  7.31510282e-01, ...,\n","                                         2.89303690e-01,  5.36759198e-01, -1.54551893e-01],\n","                                       [ 1.04597524e-01,  9.63685215e-02,  6.99654520e-02, ...,\n","                                        -4.15923089e-01, -1.18990563e-01, -6.72240138e-01],\n","                                       ...,\n","                                       [ 8.00910652e-01,  2.38983035e-01,  4.15492773e-01, ...,\n","                                         3.90533693e-02,  2.34372810e-01,  1.22278415e-01],\n","                                       [ 2.60863006e-01,  4.43266705e-02,  3.63648057e-01, ...,\n","                                        -7.53957778e-04,  3.84620689e-02, -2.14212954e-01],\n","                                       [-2.30111256e-01, -4.98388499e-01, -1.26492381e-02, ...,\n","                                         4.49868292e-01,  6.16022497e-02, -2.61357039e-01]]],\n","                                     dtype=float32)>),\n","                              ('pooler_output',\n","                               <tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n","                               array([[-0.92048556, -0.3713902 , -0.6051269 , ..., -0.44737062,\n","                                       -0.6434761 ,  0.9423272 ],\n","                                      [-0.88541585, -0.26547676,  0.21014927, ...,  0.17237046,\n","                                       -0.640299  ,  0.8888344 ]], dtype=float32)>)])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"DMmRg2X-Y7LF","executionInfo":{"status":"ok","timestamp":1619026507492,"user_tz":-180,"elapsed":4579,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["from tensorflow import keras \n","import tensorflow as tf \n","max_length = 256 \n","tokens = keras.layers.Input(shape=(max_length,), dtype=tf.dtypes.int32) \n","masks = keras.layers.Input(shape=(max_length,), dtype=tf.dtypes.int32) \n","embedding_layer = bert.layers[0]([tokens,masks])[0][:,0,:] \n","dense = tf.keras.layers.Dense(units=2, activation=\"softmax\")(embedding_layer) \n","model = keras.Model([tokens,masks],dense) "],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8xeS5TyY7No","executionInfo":{"status":"ok","timestamp":1619026510432,"user_tz":-180,"elapsed":879,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"b8ae5960-ba78-4c89-da13-7b65031ff6c9"},"source":["tokenized = tokenizer.batch_encode_plus([\"hello how is it going with you\",\"hello how is it going with you\"], return_tensors=\"tf\", max_length= max_length, truncation=True, pad_to_max_length=True) "],"execution_count":34,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGMwpG8OY7P_","executionInfo":{"status":"ok","timestamp":1619026513352,"user_tz":-180,"elapsed":896,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"d168edea-039f-4ddd-a710-24a8450e8423"},"source":["model([tokenized[\"input_ids\"],tokenized[\"attention_mask\"]]) "],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.56051177, 0.43948826],\n","       [0.56051177, 0.43948826]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b24ahO1UY7SR","executionInfo":{"status":"ok","timestamp":1619026520524,"user_tz":-180,"elapsed":767,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"2d5dbef1-2d6a-4878-fa77-73c035b8a754"},"source":["model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) \n","model.summary() "],"execution_count":37,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem (Slici (None, 768)          0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            1538        tf.__operators__.getitem[0][0]   \n","==================================================================================================\n","Total params: 109,483,778\n","Trainable params: 109,483,778\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XSCi31iUZL1Y","executionInfo":{"status":"ok","timestamp":1619026526662,"user_tz":-180,"elapsed":865,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}}},"source":["model.layers[2].trainable = False "],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcfBTBw8ZL6V","executionInfo":{"status":"ok","timestamp":1619026559585,"user_tz":-180,"elapsed":33257,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"}},"outputId":"44374850-eeab-4231-aacc-5792ea260420"},"source":["import pandas as pd \n","imdb_df = pd.read_csv(\"IMDB Dataset.csv\") \n","reviews = list(imdb_df.review) \n","tokenized_reviews = tokenizer.batch_encode_plus(reviews, return_tensors=\"tf\", max_length=max_length, truncation=True, pad_to_max_length=True) \n","\n","import numpy as np \n","train_split = int(0.8 * len(tokenized_reviews[\"attention_mask\"])) \n","train_tokens = tokenized_reviews[\"input_ids\"][:train_split] \n","test_tokens = tokenized_reviews[\"input_ids\"][train_split:] \n","train_masks = tokenized_reviews[\"attention_mask\"][:train_split] \n","test_masks = tokenized_reviews[\"attention_mask\"][train_split:] \n","sentiments = list(imdb_df.sentiment) \n","labels = np.array([[0,1] if sentiment == \"positive\" else [1,0] for sentiment in sentiments]) \n","train_labels = labels[:train_split] \n","test_labels = labels[train_split:] "],"execution_count":39,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YaQlIkdZZL8c"},"source":["model.fit([train_tokens,train_masks],train_labels, epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RTyDkLzZL-8"},"source":[""],"execution_count":null,"outputs":[]}]}